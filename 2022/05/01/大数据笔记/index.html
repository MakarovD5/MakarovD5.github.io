<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    <meta name="keywords" content="Hexo Theme Keep">
    <meta name="description" content="Hexo Theme Keep">
    <meta name="author" content="Makarov">
    
    <title>
        
            大数据笔记 |
        
        Makarov&#39;s Blog
    </title>
    
<link rel="stylesheet" href="/css/style.css">

    <link rel="shortcut icon" href="/images/logo.svg">
    <link rel="stylesheet" href="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.4.5/source/css/font-awesome.min.css">
    <script id="hexo-configurations">
    let KEEP = window.KEEP || {};
    KEEP.hexo_config = {"hostname":"example.com","root":"/","language":"en","path":"search.json"};
    KEEP.theme_config = {"toc":{"enable":true,"number":true,"expand_all":true,"init_open":true},"style":{"primary_color":"#33CC99","avatar":"/images/avatar.svg","favicon":"/images/logo.svg","article_img_align":"left","left_side_width":"260px","content_max_width":"920px","hover":{"shadow":true,"scale":true},"first_screen":{"enable":true,"background_img":"/images/bg.svg","description":"挪威的森林"},"scroll":{"progress_bar":{"enable":true},"percent":{"enable":false}}},"local_search":{"enable":true,"preload":true},"code_copy":{"enable":true,"style":"default"},"pjax":{"enable":true},"lazyload":{"enable":true},"version":"3.4.5"};
    KEEP.language_ago = {"second":"%s seconds ago","minute":"%s minutes ago","hour":"%s hours ago","day":"%s days ago","week":"%s weeks ago","month":"%s months ago","year":"%s years ago"};
  </script>
<meta name="generator" content="Hexo 6.1.0"></head>


<body>
<div class="progress-bar-container">
    
        <span class="scroll-progress-bar"></span>
    

    
        <span class="pjax-progress-bar"></span>
        <span class="pjax-progress-icon">
            <i class="fas fa-circle-notch fa-spin"></i>
        </span>
    
</div>


<main class="page-container">

    

    <div class="page-main-content">

        <div class="page-main-content-top">
            <header class="header-wrapper">

    <div class="header-content">
        <div class="left">
            
            <a class="logo-title" href="/">
                Makarov&#39;s Blog
            </a>
        </div>

        <div class="right">
            <div class="pc">
                <ul class="menu-list">
                    
                        <li class="menu-item">
                            <a class=""
                               href="/"
                            >
                                HOME
                            </a>
                        </li>
                    
                        <li class="menu-item">
                            <a class=""
                               href="/archives"
                            >
                                ARCHIVES
                            </a>
                        </li>
                    
                        <li class="menu-item">
                            <a class=""
                               href="/categories"
                            >
                                CATEGORIES
                            </a>
                        </li>
                    
                        <li class="menu-item">
                            <a class=""
                               href="/tags"
                            >
                                TAGS
                            </a>
                        </li>
                    
                    
                        <li class="menu-item search search-popup-trigger">
                            <i class="fas fa-search"></i>
                        </li>
                    
                </ul>
            </div>
            <div class="mobile">
                
                    <div class="icon-item search search-popup-trigger"><i class="fas fa-search"></i></div>
                
                <div class="icon-item menu-bar">
                    <div class="menu-bar-middle"></div>
                </div>
            </div>
        </div>
    </div>

    <div class="header-drawer">
        <ul class="drawer-menu-list">
            
                <li class="drawer-menu-item flex-center">
                    <a class=""
                       href="/">HOME</a>
                </li>
            
                <li class="drawer-menu-item flex-center">
                    <a class=""
                       href="/archives">ARCHIVES</a>
                </li>
            
                <li class="drawer-menu-item flex-center">
                    <a class=""
                       href="/categories">CATEGORIES</a>
                </li>
            
                <li class="drawer-menu-item flex-center">
                    <a class=""
                       href="/tags">TAGS</a>
                </li>
            
        </ul>
    </div>

    <div class="window-mask"></div>

</header>


        </div>

        <div class="page-main-content-middle">

            <div class="main-content">

                
                    <div class="fade-in-down-animation">
    <div class="article-content-container">

        <div class="article-title">
            <span class="title-hover-animation">大数据笔记</span>
        </div>

        
            <div class="article-header">
                <div class="avatar">
                    <img src="/images/avatar.svg">
                </div>
                <div class="info">
                    <div class="author">
                        <span class="name">Makarov</span>
                        
                            <span class="author-label">Lv1</span>
                        
                    </div>
                    <div class="meta-info">
                        <div class="article-meta-info">
    <span class="article-date article-meta-item">
        <i class="fas fa-edit"></i>&nbsp;
        <span class="pc">2022-05-01 14:52:01</span>
        <span class="mobile">2022-05-01 14:52</span>
    </span>
    
        <span class="article-categories article-meta-item">
            <i class="fas fa-folder"></i>&nbsp;
            <ul>
                
                    <li>
                        <a href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/">大数据</a>&nbsp;
                    </li>
                
            </ul>
        </span>
    
    
        <span class="article-tags article-meta-item">
            <i class="fas fa-tags"></i>&nbsp;
            <ul>
                
                    <li>
                        <a href="/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/">大数据</a>&nbsp;
                    </li>
                
            </ul>
        </span>
    

    
    
        <span class="article-wordcount article-meta-item">
            <i class="fas fa-file-word"></i>&nbsp;<span>7.4k Words</span>
        </span>
    
    
    
        <span class="article-pv article-meta-item">
            <i class="fas fa-eye"></i>&nbsp;<span id="busuanzi_value_page_pv"></span>
        </span>
    
</div>

                    </div>
                </div>
            </div>
        

        <div class="article-content markdown-body">
            <h1 id="大数据"><a href="#大数据" class="headerlink" title="大数据"></a>大数据</h1><h2 id="当前观看集数：47"><a href="#当前观看集数：47" class="headerlink" title="当前观看集数：47"></a>当前观看集数：47</h2><h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>星号（*）代表我自己的注释</p>
<h2 id="环境配置"><a href="#环境配置" class="headerlink" title="环境配置"></a>环境配置</h2><h3 id="基础Linux配置"><a href="#基础Linux配置" class="headerlink" title="基础Linux配置"></a>基础Linux配置</h3><ul>
<li><p>关防火墙</p>
</li>
<li><p>host配置，主机名设置</p>
</li>
<li><p>ssh免密</p>
</li>
<li><p>集群时间同步</p>
<p>ntpdate ntp4.aliyun.com</p>
</li>
</ul>
<h3 id="Java配置"><a href="#Java配置" class="headerlink" title="Java配置"></a>Java配置</h3><ul>
<li><p>创建统一的工作目录</p>
</li>
<li><p>解压jdk包</p>
</li>
<li><p>配置环境变量</p>
<p>记得之后更新下配置文件</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">source /etc/profile</span><br></pre></td></tr></table></figure>
</li>
<li><p>查看java安装路径</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">which java</span><br></pre></td></tr></table></figure>


</li>
<li><p>用scp复制到别的服务器，jdk和环境配置都复制，结合FinalShell全部会话命令</p>
<blockquote>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">主机名</span> </span><br><span class="line">cat /etc/hostname</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">hosts映射</span></span><br><span class="line">vim /etc/hosts</span><br><span class="line"></span><br><span class="line">127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4</span><br><span class="line">::1         localhost localhost.localdomain localhost6 localhost6.localdomain6</span><br><span class="line"></span><br><span class="line">192.168.88.151 node1.itcast.cn node1</span><br><span class="line">192.168.88.152 node2.itcast.cn node2</span><br><span class="line">192.168.88.153 node3.itcast.cn node3</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">JDK 1.8安装  上传 jdk-8u241-linux-x64.tar.gz到/export/server/目录下</span></span><br><span class="line">cd /export/server/</span><br><span class="line">tar zxvf jdk-8u241-linux-x64.tar.gz</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">	#</span><span class="language-bash">配置环境变量</span></span><br><span class="line">	vim /etc/profile</span><br><span class="line"></span><br><span class="line">	export JAVA_HOME=/export/server/jdk1.8.0_241</span><br><span class="line">	export PATH=$PATH:$JAVA_HOME/bin</span><br><span class="line">	export CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">	#</span><span class="language-bash">重新加载环境变量文件</span></span><br><span class="line">	source /etc/profile</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">集群时间同步</span></span><br><span class="line">ntpdate ntp5.aliyun.com</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">防火墙关闭</span></span><br><span class="line">firewall-cmd --state	#查看防火墙状态</span><br><span class="line">systemctl stop firewalld.service  #停止firewalld服务</span><br><span class="line">systemctl disable firewalld.service  #开机禁用firewalld服务</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">ssh免密登录（只需要配置node1至node1、node2、node3即可）</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">	#</span><span class="language-bash">node1生成公钥私钥 (一路回车)</span></span><br><span class="line">	ssh-keygen  </span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">	#</span><span class="language-bash">node1配置免密登录到node1 node2 node3</span></span><br><span class="line">	ssh-copy-id node1</span><br><span class="line">	ssh-copy-id node2</span><br><span class="line">	ssh-copy-id node3</span><br></pre></td></tr></table></figure></blockquote>
</li>
</ul>
<h3 id="Hadoop配置"><a href="#Hadoop配置" class="headerlink" title="Hadoop配置"></a>Hadoop配置</h3><ul>
<li><p>解压编译好的安装包（正常情况需要自己从源码编译或者官方编译后的）</p>
<p>为什么要编译：hadoop官方自己编译好的程序在链接动态链接库时容易出现问题，需要自己编译符合自己机器的程序</p>
</li>
<li><p>配置文件：&#x2F;export&#x2F;server&#x2F;hadoop-3.3.0&#x2F;etc&#x2F;hadoop</p>
<p>第一类1个：hadoop-env.sh</p>
<p>第二类4个：xxxx-site.xml ,site表示的是用户定义的配置，会覆盖default中的默认配置。</p>
<p>​						core-site.xml 核心模块配置</p>
<p>​						hdfs-site.xml hdfs文件系统模块配置</p>
<p>​						mapred-site.xml MapReduce模块配置</p>
<p>​						yarn-site.xml yarn模块配置</p>
<p> 第三类1个：workers</p>
<blockquote>
<p>默认配置文件内容：</p>
<p><a class="link"   target="_blank" rel="noopener" href="https://hadoop.apache.org/docs/r3.3.1/hadoop-project-dist/hadoop-common/core-default.xml" >https://hadoop.apache.org/docs/r3.3.1/hadoop-project-dist/hadoop-common/core-default.xml<i class="fas fa-external-link-alt"></i></a></p>
</blockquote>
</li>
<li><p>将Hadoop添加到环境变量</p>
</li>
<li><p>scp分发同步Hadoop安装包和环境变量profile文件</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scp -r hadoop-3.3.0 root@node2:$PWD</span><br></pre></td></tr></table></figure>
</li>
<li><p>记得之后更新下配置文件</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">source /etc/profile</span><br></pre></td></tr></table></figure>
</li>
<li><p>首次启动HDFS时，必须对其进行格式化操作。首次启动要格式化namenode，format只能进行一次 后续不再需要，只在第一台机器</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hdfs namenode -format</span><br></pre></td></tr></table></figure>



<blockquote>
<p>hadoop-env.sh</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">文件最后添加</span></span><br><span class="line">export JAVA_HOME=/export/server/jdk1.8.0_241</span><br><span class="line"></span><br><span class="line">export HDFS_NAMENODE_USER=root</span><br><span class="line">export HDFS_DATANODE_USER=root</span><br><span class="line">export HDFS_SECONDARYNAMENODE_USER=root</span><br><span class="line">export YARN_RESOURCEMANAGER_USER=root</span><br><span class="line">export YARN_NODEMANAGER_USER=root </span><br></pre></td></tr></table></figure>

<p>core-site.xml</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 设置默认使用的文件系统 Hadoop支持file、HDFS、GFS、ali|Amazon云等文件系统 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.defaultFS<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://node1:8020<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 设置Hadoop本地保存数据路径 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.tmp.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>/export/data/hadoop-3.3.0<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 设置HDFS web UI用户身份 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.http.staticuser.user<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>root<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 整合hive 用户代理设置 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.proxyuser.root.hosts<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>*<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.proxyuser.root.groups<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>*<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 文件系统垃圾桶保存时间 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.trash.interval<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>1440<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>hdfs-site.xml</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 设置SNN进程运行机器位置信息 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.secondary.http-address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>node2:9868<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>mapred-site.xml</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 设置MR程序默认运行模式： yarn集群模式 local本地模式 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.framework.name<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>yarn<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- MR程序历史服务地址 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.jobhistory.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>node1:10020<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- MR程序历史服务器web端地址 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.jobhistory.webapp.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>node1:19888<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.app.mapreduce.am.env<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>HADOOP_MAPRED_HOME=$&#123;HADOOP_HOME&#125;<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.map.env<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>HADOOP_MAPRED_HOME=$&#123;HADOOP_HOME&#125;<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.reduce.env<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>HADOOP_MAPRED_HOME=$&#123;HADOOP_HOME&#125;<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>yarn-site.xml</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 设置YARN集群主角色运行机器位置 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.hostname<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">value</span>&gt;</span>node1<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.aux-services<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>mapreduce_shuffle<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 是否将对容器实施物理内存限制 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.pmem-check-enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 是否将对容器实施虚拟内存限制。 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.vmem-check-enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 开启日志聚集 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.log-aggregation-enable<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 设置yarn历史服务器地址 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.log.server.url<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>http://node1:19888/jobhistory/logs<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 历史日志保存的时间 7天 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.log-aggregation.retain-seconds<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>604800<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>workers</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">node1.itcast.cn</span><br><span class="line">node2.itcast.cn</span><br><span class="line">node3.itcast.cn</span><br></pre></td></tr></table></figure>

<p>将hadoop添加到环境变量（3台机器）</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">vim /etc/profile</span><br><span class="line"></span><br><span class="line">export HADOOP_HOME=/export/server/hadoop-3.3.0</span><br><span class="line">export PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin</span><br><span class="line"></span><br><span class="line">source /etc/profile</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">别忘了scp给其他两台机器哦</span></span><br></pre></td></tr></table></figure></blockquote>
</li>
</ul>
<h2 id="Hadoop"><a href="#Hadoop" class="headerlink" title="Hadoop"></a>Hadoop</h2><h3 id="最初使用"><a href="#最初使用" class="headerlink" title="最初使用"></a>最初使用</h3><h4 id="shell脚本一键启停"><a href="#shell脚本一键启停" class="headerlink" title="shell脚本一键启停"></a>shell脚本一键启停</h4><p>前提：配置好机器之间的SSH免密登录和workers文件。</p>
<p>HDFS集群：<br>start-dfs.sh<br>stop-dfs.sh<br>YARN集群：<br>start-yarn.sh<br>stop-yarn.sh<br>Hadoop集群：<br>start-all.sh<br>stop-all.sh </p>
<h4 id="启动出现问题记得看日志"><a href="#启动出现问题记得看日志" class="headerlink" title="启动出现问题记得看日志"></a>启动出现问题记得看日志</h4><p>&#x2F;export&#x2F;server&#x2F;hadoop-3.3.0&#x2F;logs&#x2F;</p>
<h4 id="Web-UI"><a href="#Web-UI" class="headerlink" title="Web UI"></a>Web UI</h4><p>HDFS集群：<a class="link"   target="_blank" rel="noopener" href="http://namenode_host:9870/" >http://namenode_host:9870<i class="fas fa-external-link-alt"></i></a></p>
<p>YARN集群：<a class="link"   target="_blank" rel="noopener" href="http://resourcemanager_host:8088/" >http://resourcemanager_host:8088<i class="fas fa-external-link-alt"></i></a></p>
<h3 id="重要特性"><a href="#重要特性" class="headerlink" title="重要特性"></a>重要特性</h3><ul>
<li><p>主从架构</p>
<p>一主多从</p>
</li>
<li><p>分块存储</p>
<p>默认128M，从物理上将文件分割，存储由datanode完成</p>
</li>
<li><p>副本机制</p>
<p>默认有2个副本，即每个块在3个位置分别存储</p>
</li>
<li><p>元数据记录</p>
<p>由namenode完成，记录文件信息和块的储存位置</p>
</li>
<li><p>抽象统一的目录树结构（namespace）</p>
<p>层次型文件组织结构，即目录树</p>
</li>
</ul>
<h3 id="模拟实现分布式文件存储"><a href="#模拟实现分布式文件存储" class="headerlink" title="模拟实现分布式文件存储"></a>模拟实现分布式文件存储</h3><p>1.如何解决海量数据存的下的–<strong>分布式存储</strong></p>
<p>2.如何解决海量数据文件查询便捷—-<strong>元数据记录</strong></p>
<p>3.如何解决大文件传输效率慢—-<strong>分块存储</strong></p>
<p>4.如何解决硬件故障数据丢失–<strong>副本机制</strong></p>
<p>5.如何解决用户查询视角统一规整–<strong>抽象目录树结构</strong></p>
<h2 id="HDFS"><a href="#HDFS" class="headerlink" title="HDFS"></a>HDFS</h2><h3 id="HDFS设计目标"><a href="#HDFS设计目标" class="headerlink" title="HDFS设计目标"></a>HDFS设计目标</h3><p>\1.   HDFS集群由很多的服务器组成，而每一个机器都与可能会出现故障。HDFS为了能够进行故障检测、快速恢复等。</p>
<p>\2.   HDFS主要适合去做批量数据出来，相对于数据请求时的反应时间，HDFS更倾向于保障吞吐量。（*数据处理往往一周一次、一月一次等等，不需要考虑访问当时的反应速度）</p>
<p>\3.   典型的HDFS中的文件大小是GB到TB，HDFS比较适合存储大文件</p>
<p>\4.   HDFS很多时候是以： Write-One-Read-Many来应用的，一旦在HDFS创建一个文件，写入完后就不需要修改了。（*比如记录昨天的天气以后一定不会再修改了）</p>
<p>\5.   移动计算的代价比之移动数据的代价低。一个应用请求的计算，离它操作的数据越近就越高效。将计算移动到数据附近，比之将数据移动到应用所在显然更好。</p>
<h3 id="Shell"><a href="#Shell" class="headerlink" title="Shell"></a>Shell</h3><p>hadoop fs [generic options]</p>
<h4 id="文件系统协议"><a href="#文件系统协议" class="headerlink" title="文件系统协议"></a>文件系统协议</h4><p>hadoop fs -ls file:&#x2F;&#x2F;&#x2F; #操作本地文件系统<br>hadoop fs -ls hdfs:&#x2F;&#x2F;node1:8020&#x2F; #操作HDFS分布式文件系统<br>hadoop fs -ls &#x2F; #直接根目录，没有指定协议 将加载读取<strong>fs.defaultFS</strong>值</p>
<p>hadoop dfs 只能操作HDFS文件系统（包括与Local FS间的操作），不过已经Deprecated；<br>hdfs dfs 只能操作HDFS文件系统相关（包括与Local FS间的操作）,常用；<br>hadoop fs 可操作任意文件系统，不仅仅是hdfs文件系统，使用范围更广；<br>目前版本来看，官方最终推荐使用的是hadoop fs。当然hdfs dfs在市面上的使用也比较多。<br>可以通过hadoop fs -help命令来查看每个命令的详细用法。(*看完help就相当于看完所有的shell命令，极大提高功力)</p>
<h4 id="常用命令"><a href="#常用命令" class="headerlink" title="常用命令"></a>常用命令</h4><h5 id="创建文件夹"><a href="#创建文件夹" class="headerlink" title="创建文件夹"></a>创建文件夹</h5><p>hadoop fs -mkdir [-p] <path> …<br>path 为待创建的目录<br>-p选项的行为与Unix mkdir -p非常相似，它会沿着路径创建父目录。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -mkdir /itcast</span><br></pre></td></tr></table></figure>

<h5 id="查看指定目录下内容"><a href="#查看指定目录下内容" class="headerlink" title="查看指定目录下内容"></a>查看指定目录下内容</h5><p>hadoop fs -ls [-h] [-R] [<path> …]<br>path 指定目录路径<br>-h 人性化显示文件size<br>-R 递归查看指定目录及其子目录</p>
<h5 id="上传文件到HDFS指定目录下"><a href="#上传文件到HDFS指定目录下" class="headerlink" title="上传文件到HDFS指定目录下"></a>上传文件到HDFS指定目录下</h5><p> hadoop fs -put [-f] [-p] <localsrc> … <dst><br>-f 覆盖目标文件（已存在下）<br>-p 保留访问和修改时间，所有权和权限。<br>localsrc 本地文件系统（<strong>客户端所在机器</strong>）<br>dst 目标文件系统（HDFS）</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -put zookeeper.out /itcast</span><br><span class="line">hadoop fs -put file:///etc/profile hdfs://node1:8020/itcast</span><br></pre></td></tr></table></figure>

<p><strong>moveFromLocal</strong><br>和put参数类似，但是源文件localsrc拷贝之后自身被删除<br>hdfs dfs **-**moveFromLocal <strong>&lt;**localsrc**&gt;</strong> <strong>&lt;**dst**&gt;</strong></p>
<h5 id="查看HDFS文件内容"><a href="#查看HDFS文件内容" class="headerlink" title="查看HDFS文件内容"></a>查看HDFS文件内容</h5><p>hadoop fs -cat <src> …<br>读取指定文件全部内容，显示在标准输出控制台。<br>注意：对于大文件内容读取，慎重。（*可用head和tail命令）</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -cat /itcast/zookeeper.out</span><br></pre></td></tr></table></figure>

<p><strong>head 命令</strong></p>
<p>hdfs dfs -head URI</p>
<p><strong>tail 命令</strong></p>
<p>hdfs dfs -tail [-f] URI</p>
<p>-f选项表示数据只要有变化也会输出到控制台。</p>
<h5 id="下载HDFS文件"><a href="#下载HDFS文件" class="headerlink" title="下载HDFS文件"></a>下载HDFS文件</h5><p>hadoop fs -get [-f] [-p] <src> … <localdst><br>下载文件到本地文件系统指定目录，localdst必须是目录<br>-f 覆盖目标文件（已存在下）<br>-p 保留访问和修改时间，所有权和权限。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[root@node2 ~]# mkdir test</span><br><span class="line">[root@node2 ~]# cd test/</span><br><span class="line">[root@node2 test]# ll</span><br><span class="line">total 0</span><br><span class="line">[root@node2 test]# hadoop fs -get /itcast/zookeeper.out ./</span><br><span class="line">（*./代表当前路径）</span><br><span class="line">[root@node2 test]# ll</span><br><span class="line">total 20</span><br><span class="line">-rw-r--r-- 1 root root 18213 Aug 18 17:54 zookeeper.out</span><br></pre></td></tr></table></figure>

<p><strong>合并下载getmerge</strong></p>
<p>hadoop fs -getmerge [-nl] [-skip-empty-file] <src> <localdst><br>    下载多个文件合并到本地文件系统的一个文件中。<br>    -nl选项表示在每个文件末尾添加换行符<br>    -skip-empty-file跳过空文件</p>
<h5 id="拷贝HDFS文件"><a href="#拷贝HDFS文件" class="headerlink" title="拷贝HDFS文件"></a>拷贝HDFS文件</h5><p>hadoop fs -cp [-f] <src> … <dst><br>-f 覆盖目标文件（已存在下）</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[root@node3 ~]# hadoop fs -cp /small/1.txt /itcast</span><br><span class="line">[root@node3 ~]# hadoop fs -cp /small/1.txt /itcast/666.txt #重命令</span><br><span class="line">[root@node3 ~]# hadoop fs -ls /itcast</span><br><span class="line">Found 4 items</span><br><span class="line">-rw-r--r-- 3 root supergroup 2 2021-08-18 17:58 /itcast/1.txt</span><br><span class="line">-rw-r--r-- 3 root supergroup 2 2021-08-18 17:59 /itcast/666.txt</span><br></pre></td></tr></table></figure>

<h5 id="追加数据到HDFS文件中"><a href="#追加数据到HDFS文件中" class="headerlink" title="追加数据到HDFS文件中"></a>追加数据到HDFS文件中</h5><p>hadoop fs -appendToFile <localsrc> … <dst><br>将所有给定本地文件的内容追加到给定dst文件。<br>dst如果文件不存在，将创建该文件。<br>如果<localSrc>为-，则输入为从标准输入中读取。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">追加内容到文件尾部 appendToFile</span></span><br><span class="line">[root@node3 ~]# echo 1 &gt;&gt; 1.txt</span><br><span class="line">[root@node3 ~]# echo 2 &gt;&gt; 2.txt </span><br><span class="line">[root@node3 ~]# echo 3 &gt;&gt; 3.txt </span><br><span class="line">[root@node3 ~]# hadoop fs -appendToFile *.txt /1.txt</span><br><span class="line">（*若1.txt有内容则追加到其后面，没有这个文件就新建这个文件）</span><br><span class="line">[root@node3 ~]# hadoop fs -cat /1.txt</span><br><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td></tr></table></figure>

<h5 id="HDFS数据移动操作"><a href="#HDFS数据移动操作" class="headerlink" title="HDFS数据移动操作"></a>HDFS数据移动操作</h5><p>hadoop fs -mv <src> … <dst><br>移动文件到指定文件夹下<br>可以使用该命令移动数据，重命名文件的名称</p>
<h5 id="查看HDFS磁盘使用情况"><a href="#查看HDFS磁盘使用情况" class="headerlink" title="查看HDFS磁盘使用情况"></a>查看HDFS磁盘使用情况</h5><p>hdfs dfs -df [-h] URI [URI …]</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@node1 ~]# hdfs dfs -df -h /</span><br><span class="line">Filesystem                      Size   Used  Available  Use%</span><br><span class="line">hdfs://node1.itcast.cn:9820  346.6 G  2.1 G    236.7 G    1%</span><br></pre></td></tr></table></figure>

<h5 id="显示目录中所有文件大小"><a href="#显示目录中所有文件大小" class="headerlink" title="显示目录中所有文件大小"></a>显示目录中所有文件大小</h5><p><strong>du 命令</strong></p>
<p>显示目录中所有文件大小，当只指定一个文件时，显示此文件的大小。</p>
<p>语法格式：<br>hdfs dfs -du [-s] [-h] [-v] [-x]  URI [URI …]  </p>
<p>命令选项：<br>-s：表示显示文件长度的汇总摘要，而不是单个文件的摘要。<br>-h：选项将以“人类可读”的方式格式化文件大小<br>-v：选项将列名显示为标题行。<br>-x：选项将从结果计算中排除快照。 </p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@node1 ~]# hdfs dfs -du -s -h -v /source/weibo/</span><br><span class="line">SIZE    DISK_SPACE_CONSUMED_WITH_ALL_REPLICAS  FULL_PATH_NAME</span><br><span class="line">64.2 M  192.6 M                                /source/weibo</span><br></pre></td></tr></table></figure>

<h5 id="修改HDFS文件副本个数"><a href="#修改HDFS文件副本个数" class="headerlink" title="修改HDFS文件副本个数"></a>修改HDFS文件副本个数</h5><p>hadoop fs -setrep [-R] [-w] <rep> <path> …<br>    修改指定文件的副本个数。<br>    -R表示递归 修改文件夹下及其所有<br>    -w 客户端是否等待副本修改完毕。<br>    <rep>副本数</p>
<p>（*最好提前规划好副本数，不然后面在进行这个setrep操作会很浪费时间资源）</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -setrep -w 2 /tmp/caixukun_dirtydata.csv</span><br></pre></td></tr></table></figure>



<h5 id="命令官方指导文档"><a href="#命令官方指导文档" class="headerlink" title="命令官方指导文档"></a>命令官方指导文档</h5><p><a class="link"   target="_blank" rel="noopener" href="https://hadoop.apache.org/docs/r3.3.0/hadoop-project-dist/hadoop-common/FileSystemShell.html" >Apache Hadoop 3.3.0 – Overview<i class="fas fa-external-link-alt"></i></a></p>
<h3 id="HDFS-Java-客户端-API"><a href="#HDFS-Java-客户端-API" class="headerlink" title="HDFS Java 客户端 API"></a>HDFS Java 客户端 API</h3><h4 id="客户端核心类"><a href="#客户端核心类" class="headerlink" title="客户端核心类"></a>客户端核心类</h4><p>Configuration：该类的对象封转了客户端或者服务器的配置</p>
<p>FileSystem：该类的对象是一个文件系统对象，可以用该对象的一些方法来对文件进行操作，通过FileSystem的静态方法get获得该对象。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">FileSystem</span> <span class="variable">fs</span> <span class="operator">=</span> FileSystem.get(conf)</span><br></pre></td></tr></table></figure>

<ul>
<li>get方法从conf中的一个参数 fs.defaultFS的配置值判断具体是什么类型的文件系统。如果我们的代码中没有指定fs.defaultFS，并且工程classpath下也没有给定相应的配置，conf中的默认值就来自于hadoop的jar包中的core-default.xml，默认值为： file:&#x2F;&#x2F;&#x2F;，则获取的将不是一个DistributedFileSystem的实例，而是一个本地文件系统的客户端对象。</li>
</ul>
<h4 id="配置Maven"><a href="#配置Maven" class="headerlink" title="配置Maven"></a>配置Maven</h4><p>配置pom.xml</p>
<p>配置阿里源</p>
<p>maven-compiler-plugin插件报错：<br>安装maven仓库里有该插件的maven版本，安装后一定要<strong>重启idea</strong></p>
<p>（*需不需要重启idea我自己总结一条规律：是不是自行懂了）</p>
<h4 id="连接HDFS"><a href="#连接HDFS" class="headerlink" title="连接HDFS"></a>连接HDFS</h4><p>用单元测试的方式连接，添加@Before和@After</p>
<h5 id="修改默认用户"><a href="#修改默认用户" class="headerlink" title="修改默认用户"></a>修改默认用户</h5><p>默认以windwos的用户登录，需要修改为root</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//设置客户端身份 以具备权限在HDFS操作</span></span><br><span class="line">System.setProperty(<span class="string">&quot;HADOOP_USER_NAME&quot;</span>,<span class="string">&quot;root&quot;</span>);</span><br></pre></td></tr></table></figure>

<h5 id="创建文件夹-1"><a href="#创建文件夹-1" class="headerlink" title="创建文件夹"></a>创建文件夹</h5><p>mkdir()</p>
<h5 id="上传文件"><a href="#上传文件" class="headerlink" title="上传文件"></a>上传文件</h5><p>copyFromLocalFile()</p>
<h5 id="下载文件"><a href="#下载文件" class="headerlink" title="下载文件"></a>下载文件</h5><p>copyToLocalFile()</p>
<p><strong>下载报错</strong></p>
<p>错误提示：<br>    找不到winutils.exe、HADOOP_HOME没有设置<br>原因：<br>    Hadoop访问windows本地文件系统，要求Windows上的本地库能正常工作。<br>    其中Hadoop使用某些Windows API来实现类似posix的文件访问权限。<br>    上述功能需要在hadoop.dll和winutils.exe来实现。<br>解决：<br>    下载Hadoop源码在windows平台编译，编译出windows本地库。然后配置Hadoop环境变量。<br>HADOOP_HOME&#x3D;C:\soft\hadoop-3.1.4<br>path&#x3D;;%HADOOP_HOME%\bin</p>
<h4 id="Log4J"><a href="#Log4J" class="headerlink" title="Log4J"></a>Log4J</h4><h5 id="Log4j具有三个主要组件"><a href="#Log4j具有三个主要组件" class="headerlink" title="Log4j具有三个主要组件"></a>Log4j具有三个主要组件</h5><ul>
<li>Logger(日志记录器)<br>Logger控制日志的输出级别与日志是否输出；</li>
<li>Appender（输出端）<br>Appender指定日志的输出方式（ConsoleAppender控制台、FileAppender文件、JDBCAppender等）</li>
<li>Layout（日志格式化器）<br>Layout控制日志信息的输出格式（simple格式、HTML格式、PatternLayout自定义格式）</li>
</ul>
<h5 id="日志级别"><a href="#日志级别" class="headerlink" title="日志级别"></a>日志级别</h5><p>Log4J 在 org.apache.log4j.Level 类中定义了OFF、FATAL、ERROR、WARN、INFO、DEBUG、TRACE、ALL八种日志级别</p>
<p>ERROR &gt; WARN &gt; INFO &gt; DEBUG</p>
<table>
<thead>
<tr>
<th>目录</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td>ERROR</td>
<td>发生错误事件，但仍不影响系统的继续运行</td>
</tr>
<tr>
<td>WARN</td>
<td>警告，即潜在的错误情形</td>
</tr>
<tr>
<td>INFO</td>
<td>一般在粗粒度级别上，强调应用程序的运行全程</td>
</tr>
<tr>
<td>DEBUG</td>
<td>一般用于细粒度级别上，对调试应用程序非常有帮助</td>
</tr>
</tbody></table>
<h5 id="程序中使用Log4j"><a href="#程序中使用Log4j" class="headerlink" title="程序中使用Log4j"></a>程序中使用Log4j</h5><ul>
<li>项目中引入log4j的jar包</li>
<li>添加配置文件log4j.properties</li>
<li>代码中使用</li>
</ul>
<h6 id="项目中引入log4j的jar包"><a href="#项目中引入log4j的jar包" class="headerlink" title="项目中引入log4j的jar包"></a>项目中引入log4j的jar包</h6><p>hadoop自带log4j，可以不用自己再安装，在依赖项的hadoop-common里</p>
<h6 id="配置文件log4j-properties"><a href="#配置文件log4j-properties" class="headerlink" title="配置文件log4j.properties"></a>配置文件log4j.properties</h6><p>可以在Hadoop安装路径里拿取：&#x2F;export&#x2F;server&#x2F;hadoop-3.3.0&#x2F;etc&#x2F;hadoop&#x2F;</p>
<figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#ConsoleAppender表示控制台，</span></span><br><span class="line"><span class="attr">log4j.appender.Console</span>=<span class="string">org.apache.log4j.ConsoleAppender</span></span><br><span class="line"><span class="comment">#自定义格式</span></span><br><span class="line"><span class="attr">log4j.appender.Console.layout</span>=<span class="string">org.apache.log4j.PatternLayout</span></span><br><span class="line"><span class="comment">#格式形式为时间，进程等等。。。</span></span><br><span class="line"><span class="attr">log4j.appender.Console.layout.ConversionPattern</span>=<span class="string">%d [%t] %p [%c] - %m%n</span></span><br><span class="line"><span class="comment">#DEBUG表示级别，只显示DEBUG及以上的级别，如果为info，则debug及以下级别的不会输出。warn等等同理</span></span><br><span class="line"><span class="comment">#Consle只是个名字，起其他任何名字都行</span></span><br><span class="line"><span class="attr">log4j.rootLogger</span>=<span class="string">DEBUG,Console</span></span><br></pre></td></tr></table></figure>

<p>ConversionPattern的格式：</p>
<p>%p: 输出日志信息优先级，即DEBUG，INFO，WARN，ERROR，FATAL,<br>%d: 输出日志时间点的日期或时间，默认格式为ISO8601，也可以在其后指定格式，比如：%d{yyyy-MM-dd HH:mm:ss,SSS}，输出类似：2011-10-18 22:10:28,921<br> %r: 输出自应用启动到输出该log信息耗费的毫秒数<br> %c: 输出日志信息所属的类目，通常就是所在类的全名<br> %t: 输出产生该日志事件的线程名<br> %l: 输出日志事件的发生位置，相当于%C.%M(%F:%L)的组合,包括类目名、发生的线程，以及在代码中的行数。<br> %x: 输出和当前线程相关联的NDC(嵌套诊断环境),尤其用到像java servlets这样的多客户多线程的应用中。<br> %%: 输出一个”%”字符<br> %F: 输出日志消息产生时所在的文件名称<br> %L: 输出代码中的行号<br> %m: 输出代码中指定的消息,产生的日志具体信息<br> %n: 输出一个回车换行符，Windows平台为”\r\n”，Unix平台为”\n”输出日志信息换行 </p>
<h6 id="代码中使用"><a href="#代码中使用" class="headerlink" title="代码中使用"></a>代码中使用</h6><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">Logger</span> <span class="variable">logger</span> <span class="operator">=</span> Logger.getLogger(对哪个类的记录的类的类名.class)</span><br></pre></td></tr></table></figure>

<h4 id="Google-option"><a href="#Google-option" class="headerlink" title="Google-option"></a>Google-option</h4><p>创建实体类，创建命令行对应public字段，每个字段加@Option</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">ServerOptions</span> <span class="keyword">extends</span> <span class="title class_">OptionsBase</span> &#123;</span><br><span class="line">  <span class="meta">@Option(</span></span><br><span class="line"><span class="meta">      name = &quot;help&quot;,</span></span><br><span class="line"><span class="meta">      abbrev = &#x27;h&#x27;,</span></span><br><span class="line"><span class="meta">      help = &quot;Prints usage info.&quot;,</span></span><br><span class="line"><span class="meta">      defaultValue = &quot;true&quot;</span></span><br><span class="line"><span class="meta">    )</span></span><br><span class="line">  <span class="keyword">public</span> <span class="type">boolean</span> help;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>使用：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">OptionsParser</span> <span class="variable">parser</span> <span class="operator">=</span> OptionsParser.newOptionsParser(ServerOptions.class);</span><br><span class="line">parser.parseAndExitUponError(args);</span><br><span class="line"><span class="type">ServerOptions</span> <span class="variable">options</span> <span class="operator">=</span> parser.getOptions(ServerOptions.class);</span><br></pre></td></tr></table></figure>

<h4 id="舆情数据上报案例"><a href="#舆情数据上报案例" class="headerlink" title="舆情数据上报案例"></a>舆情数据上报案例</h4><h5 id="环境准备"><a href="#环境准备" class="headerlink" title="环境准备"></a>环境准备</h5><p>Google-option</p>
<p>Log4J</p>
<p>FileSystem类的使用，非常频繁</p>
<h5 id="实现生成数据采集任务"><a href="#实现生成数据采集任务" class="headerlink" title="实现生成数据采集任务"></a>实现生成数据采集任务</h5><p>实现步骤：<br>    1.判断原始数据目录是否存在<br>    2.读取原始数据目录下的所有文件<br>    3.判断待上传目录是否存在，不存在则创建一个<br>    4.创建任务目录（目录名称：task_年月日时分秒_任务状态）<br>    5.遍历待上传的文件，在待上传目录生成一个willDoing文件<br>    6.将待移动的文件添加到willDoing文件中</p>
<p>知识点：</p>
<p>1、try-catch的catch部分改为用log4j输出到控制台：<strong>（*为什么要再抛一个新的异常目前不清楚，可能为打印出具体错误行数栈）</strong></p>
<p><strong>在catch子句中可以抛出一个异常， 这样做的目的是 改变异常类型；强烈建议使用这种包装技术， 这样可以让用户抛出子系统中的高级异常， 而不会丢失原始异常的小细节；</strong></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Logger.error(e.getMessage(), e);</span><br><span class="line"><span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">RuntimeException</span>(e.getMessage());</span><br></pre></td></tr></table></figure>

<p>2、lambda函数：在文章尾部其他领域java部分</p>
<p>3、如果路径不存在，新建路径</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">FileUtils.forceMkdirParent(tempDir);</span><br></pre></td></tr></table></figure>

<p>4、FileUtils的使用</p>
<h5 id="实现执行数据上报任务"><a href="#实现执行数据上报任务" class="headerlink" title="实现执行数据上报任务"></a>实现执行数据上报任务</h5><p>实现步骤：</p>
<ol>
<li><pre><code>读取待上传目录的willDoing任务文件，注意过滤COPY和DONE后的任务文件夹
</code></pre>
</li>
<li><pre><code>遍历读取任务文件，开始上传
</code></pre>
 a)	将任务文件修改为COPY，表示正在处理中<br> b)	获取任务的日期<br> c)	判断HDFS目标上传目录是否存在，不存在则创建<br> d)	读取任务文件<br> e)	按照换行符切分<br> f)	上传每一个文件,调用HDFSUtils进行数据文件上传<br> g)	上传成功后，将COPY后缀修改为_DONE</li>
</ol>
<p>(*思路总结，source是从网上爬的数据，按任务分类整理好挪到pending下，再统一上传到hdfs上)</p>
<h3 id="Hadoop基准测试"><a href="#Hadoop基准测试" class="headerlink" title="Hadoop基准测试"></a>Hadoop基准测试</h3><h4 id="写入基准测试"><a href="#写入基准测试" class="headerlink" title="写入基准测试"></a>写入基准测试</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop jar /export/server/hadoop-3.1.4/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.1.4-tests.jar  TestDFSIO -write -nrFiles 10  -fileSize 10MB</span><br></pre></td></tr></table></figure>

<h4 id="读取基准测试"><a href="#读取基准测试" class="headerlink" title="读取基准测试"></a>读取基准测试</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop jar /export/server/hadoop-3.1.4/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.1.4-tests.jar  TestDFSIO -read -nrFiles 10 -fileSize 10MB</span><br></pre></td></tr></table></figure>

<h4 id="清除测试数据"><a href="#清除测试数据" class="headerlink" title="清除测试数据"></a>清除测试数据</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop jar /export/server/hadoop-3.1.4/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.1.4-tests.jar   TestDFSIO -clean</span><br></pre></td></tr></table></figure>

<h4 id="测试结果各项数值的意义"><a href="#测试结果各项数值的意义" class="headerlink" title="测试结果各项数值的意义"></a>测试结果各项数值的意义</h4><ul>
<li><code>Number of files</code>：生成 mapTask 数量，一般是集群中 CPU 核数 -1，我们测试虚拟机就按照实际的物理内存 -1 分配即可</li>
<li><code>Total MBytes processed</code>：单个 map 处理的文件大小</li>
<li><code>Throughput mb/sec</code>：单个 mapTak 的吞吐量</li>
</ul>
<p>计算方式：处理的总文件大小 &#x2F; 每一个 mapTask 写数据的时间累加<br> 集群整体吞吐量：生成 mapTask 数量 * 单个 mapTak 的吞吐量</p>
<ul>
<li><code>Average IO rate mb/sec</code>：平均 mapTak 的吞吐量</li>
</ul>
<p>计算方式：每个 mapTask 处理文件大小 &#x2F; 每一个 mapTask 写数据的时间全部相加除以 task 数量</p>
<ul>
<li><code>IO rate std deviation</code>：方差、反映各个 mapTask 处理的差值，越小越均衡</li>
</ul>
<h3 id="HDFS工作流程与机制"><a href="#HDFS工作流程与机制" class="headerlink" title="HDFS工作流程与机制"></a>HDFS工作流程与机制</h3><h4 id="HDFS集群角色与职责"><a href="#HDFS集群角色与职责" class="headerlink" title="HDFS集群角色与职责"></a>HDFS集群角色与职责</h4><h5 id="NameNode"><a href="#NameNode" class="headerlink" title="NameNode"></a>NameNode</h5><ul>
<li>NameNode成为了访问HDFS的唯一入口。</li>
<li>NameNode仅存储HDFS的元数据：文件系统中所有文件的目录树，并跟踪整个集群中的文件，不存储实际数据。</li>
<li>NameNode知道HDFS中任何给定文件的块列表及其位置。使用此信息NameNode知道如何从块中构建文件。</li>
<li>NameNode不持久化存储每个文件中各个块所在的datanode的位置信息，这些信息会在系统启动时从DataNode重建。</li>
<li>NameNode是Hadoop集群中的单点故障。</li>
<li>NameNode所在机器通常会配置有大量内存（RAM）。</li>
</ul>
<h5 id="DataNode"><a href="#DataNode" class="headerlink" title="DataNode"></a>DataNode</h5><ul>
<li>DataNode是Hadoop HDFS中的从角色，负责具体的数据块存储。决定了HDFS集群的整体数据存储能力。</li>
<li>DataNode负责最终数据块block的存储。是集群的从角色，也称为Slave。</li>
<li>DataNode启动时，会将自己注册到NameNode并汇报自己负责持有的块列表。</li>
<li>当某个DataNode关闭时，不会影响数据的可用性。 NameNode将安排由其他DataNode管理的块进行副本复制。</li>
<li>DataNode所在机器通常配置有大量的硬盘空间，因为实际数据存储在DataNode中。</li>
</ul>
<h5 id="SecondaryNameNode"><a href="#SecondaryNameNode" class="headerlink" title="SecondaryNameNode"></a>SecondaryNameNode</h5><ul>
<li>Secondary NameNode充当NameNode的辅助节点，但不能替代NameNode。</li>
<li>主要是帮助主角色进行元数据文件的合并动作。可以通俗的理解为主角色的“秘书”。</li>
</ul>
<h4 id="HDFS读写数据流程"><a href="#HDFS读写数据流程" class="headerlink" title="HDFS读写数据流程"></a>HDFS读写数据流程</h4><p>*读写流程面试常考，面试前可以看源码解析了解流程</p>
<h5 id="Pipeline管道"><a href="#Pipeline管道" class="headerlink" title="Pipeline管道"></a>Pipeline管道</h5><ul>
<li>pipeline是线性传输，顺序的沿着一个方向传输，这样能够充分利用每个机器的带宽，避免网络瓶颈和高延迟时 的连接，最小化推送所有数据的延时。</li>
</ul>
<h5 id="ACK应答响应"><a href="#ACK应答响应" class="headerlink" title="ACK应答响应"></a>ACK应答响应</h5><ul>
<li>ACK (Acknowledge character）即是确认字符，在数据通信中，接收方发给发送方的一种传输类控制字符。表示发来的数据已确认接收无误。</li>
<li>在HDFS pipeline管道传输数据的过程中，传输的反方向会进行ACK校验，确保数据传输安全。</li>
</ul>
<h5 id="默认3副本存储策略"><a href="#默认3副本存储策略" class="headerlink" title="默认3副本存储策略"></a>默认3副本存储策略</h5><ul>
<li>默认副本存储策略是由BlockPlacementPolicyDefault指定。</li>
<li>第一块副本：优先客户端本地，否则随机<br>第二块副本：不同于第一块副本的不同机架。（*机架就是一个衣柜样的机柜）<br>第三块副本：第二块副本相同机架不同机器。</li>
</ul>
<h2 id="MapReduce"><a href="#MapReduce" class="headerlink" title="MapReduce"></a>MapReduce</h2><h2 id="其他领域"><a href="#其他领域" class="headerlink" title="其他领域"></a>其他领域</h2><h3 id="Java"><a href="#Java" class="headerlink" title="Java"></a>Java</h3><h4 id="lambda的使用"><a href="#lambda的使用" class="headerlink" title="lambda的使用"></a>lambda的使用</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 读取原始数据目录下的所有文件</span></span><br><span class="line">File[] allSourceDataFile = sourceDir.listFiles(f -&gt; &#123;</span><br><span class="line">    <span class="comment">// 判断文件格式是否以 weibo_data_ 开头</span></span><br><span class="line">    <span class="type">String</span> <span class="variable">fileName</span> <span class="operator">=</span> f.getName();</span><br><span class="line">    <span class="keyword">if</span> (fileName.startsWith(<span class="string">&quot;weibo_data_&quot;</span>)) &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure>

<p>这里的listFiles()括号里的内容可以理解为：</p>
<p>首先，listFiles的参数形式有三种：空，FileFilter接口，FilenameFilter接口</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//分别看看接口的样子</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">interface</span> <span class="title class_">FileFilter</span> &#123;</span><br><span class="line">    <span class="type">boolean</span> <span class="title function_">accept</span><span class="params">(File pathname)</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">interface</span> <span class="title class_">FilenameFilter</span> &#123;</span><br><span class="line">    <span class="type">boolean</span> <span class="title function_">accept</span><span class="params">(File dir, String name)</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>lambda函数实现了FileFilter接口<br>为什么是FileFilter而不是FilenameFilter：因为lambda只有一个参数f，而FilenameFilter需要两个参数。</p>
<p>FileFilter中只有一个抽象方法，返回的是Boolean型，所以lambda函数就实现了这个方法。</p>
<p>总的来看：lambda返回的是FileFilter接口的实例对象，只有一个f参数，且f为File类型参数，lambda的{}内实现了accept方法，该方法返回的是boolean型。</p>
<p>使用Lambda时，要记住的就两点：</p>
<ol>
<li>Lambda返回的是接口的实例对象</li>
<li>有没有参数、参数有多少个、需不需要有返回值、返回值的类型是什么—-&gt;<strong>选择自己合适的函数式接口</strong></li>
<li><strong>（*Lambda只能实现函数式接口，即只有一个抽象方法的接口，用@FunctionalInterface标注函数式接口，所以如果接口有两个抽象方法就无法使用lambda）</strong></li>
</ol>
<h4 id="FileUtils的使用"><a href="#FileUtils的使用" class="headerlink" title="FileUtils的使用"></a>FileUtils的使用</h4><p> FileUtils 是 Apache Commons IO 的一部分</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>commons-io<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>commons-io<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.6<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>

<h5 id="FileUtils-moveFile"><a href="#FileUtils-moveFile" class="headerlink" title="FileUtils.moveFile"></a>FileUtils.moveFile</h5><p>When the destination file is on another file system, do a “copy and delete”.</p>
<h4 id="捕获异常-再次抛出异常与异常链"><a href="#捕获异常-再次抛出异常与异常链" class="headerlink" title="捕获异常+再次抛出异常与异常链"></a>捕获异常+再次抛出异常与异常链</h4><p>在catch子句中可以抛出一个异常， 这样做的目的是 改变异常类型；强烈建议使用这种包装技术， 这样可以让用户抛出子系统中的高级异常， 而不会丢失原始异常的小细节；</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line"><span class="comment">//            e.printStackTrace();</span></span><br><span class="line">            logger.error(e.getMessage(),e);</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">RuntimeException</span>(e);</span><br><span class="line">        &#125;</span><br></pre></td></tr></table></figure>

<h4 id="JAVA-IO"><a href="#JAVA-IO" class="headerlink" title="JAVA IO"></a>JAVA IO</h4><h5 id="创建文件"><a href="#创建文件" class="headerlink" title="创建文件"></a>创建文件</h5><ol>
<li>new File(String path);</li>
<li>new File(File father, String chilend);</li>
<li>new File(String father, String child);</li>
</ol>
<h5 id="获取文件信息"><a href="#获取文件信息" class="headerlink" title="获取文件信息"></a>获取文件信息</h5><ol>
<li>getName();</li>
<li>getAbsolutePath();</li>
<li>getParent();</li>
<li>length();&#x2F;&#x2F;字节数，英文1个字节，汉字3个字节</li>
<li>exists();</li>
<li>isFile();</li>
<li>isDirectory();</li>
</ol>
<h5 id="目录操作"><a href="#目录操作" class="headerlink" title="目录操作"></a>目录操作</h5><ol>
<li>delete();&#x2F;&#x2F;删除文件和空文件夹，文件夹里有文件就不行，目录</li>
<li>mkdir();</li>
<li>mkdirs();&#x2F;&#x2F;递归创建</li>
</ol>
<h3 id="Linux"><a href="#Linux" class="headerlink" title="Linux"></a>Linux</h3><h4 id="proc目录"><a href="#proc目录" class="headerlink" title="proc目录"></a>proc目录</h4><p>&#x2F;proc是一个位于内存中的伪文件系统(in-memory pseudo-file system)。该目录下保存的不是真正的文件和目录，而是一些“运行时”信息，如系统内存、磁盘io、设备挂载信息和硬件配置信息等。</p>
<p>lsmod命令就是cat &#x2F;proc&#x2F;modules命令的别名，lspci命令是cat &#x2F;proc&#x2F;pci命令的别名。</p>
<ul>
<li>&#x2F;proc&#x2F;loadavg 保存了系统负载的平均值，其前三列分别表示最近1分钟、5分钟及15分的平均负载。反映了当前系统的繁忙情况。</li>
<li>&#x2F;proc&#x2F;meminfo 当前内存使用的统计信息，常由free命令使用；可以使用文件查看命令直接读取此文件，其内容显示为两列，前者为统计属性，后者为对应的值；</li>
<li>&#x2F;proc&#x2F;diskstats 磁盘设备的磁盘I&#x2F;O统计信息列表;</li>
<li>&#x2F;proc&#x2F;net&#x2F;dev 网络流入流出的统计信息，包括接收包的数量、发送包的数量，发送数据包时的错误和冲突情况等。</li>
<li>&#x2F;proc&#x2F;cmdline 在启动时传递至内核的启动参数，通常由grub启动管理工具进行传递；</li>
<li>&#x2F;proc&#x2F;devices 系统已经加载的所有块设备和字符设备的信息；</li>
<li>&#x2F;proc&#x2F;mounts 系统中当前挂载的所有文件系统；</li>
<li>&#x2F;proc&#x2F;partitions 块设备每个分区的主设备号（major）和次设备号（minor）等信息，同时包括每个分区所包含的块（block）数目；</li>
<li>&#x2F;proc&#x2F;uptime 系统上次启动以来的运行时间；</li>
<li>&#x2F;proc&#x2F;version 当前系统运行的内核版本号，在作者的Debian系统中，还会显示系统安装的gcc版本；</li>
<li>&#x2F;proc&#x2F;vmstat 当前系统虚拟内存的统计数据。</li>
</ul>
<h4 id="scp命令：基于ssh远程拷贝"><a href="#scp命令：基于ssh远程拷贝" class="headerlink" title="scp命令：基于ssh远程拷贝"></a>scp命令：基于ssh远程拷贝</h4><p>scp 是 secure copy 的缩写, scp 是 linux 系统下基于 ssh 登陆进行安全的远程文件拷贝命令。可以结合SSH免密，并设置host地址，把IP数字设置成简短的英文名</p>
<p>参数-r： 递归复制整个目录。复制目录时要加-r</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scp -r jdk1.8.0_241 root@node2:/export/server/</span><br></pre></td></tr></table></figure>

<h4 id="FinalShell的命令编辑器能发送到全部会话"><a href="#FinalShell的命令编辑器能发送到全部会话" class="headerlink" title="FinalShell的命令编辑器能发送到全部会话"></a>FinalShell的命令编辑器能发送到全部会话</h4><h3 id="IDEA"><a href="#IDEA" class="headerlink" title="IDEA"></a>IDEA</h3><h4 id="pom报错"><a href="#pom报错" class="headerlink" title="pom报错"></a>pom报错</h4><p>如果手动修改了本地文件，pom报错，重启一下idea，因为idea无法动态识别</p>
<h4 id="快速选中一行"><a href="#快速选中一行" class="headerlink" title="快速选中一行"></a>快速选中一行</h4><p>一、鼠标连续点三下<br>二、end键将光标移到行尾 ， ctrl+w 选中行<br>三、end键将光标移到行尾 ， shift + home 选中行<br>四、home 键 光标移到行首、然后 点击shift +end</p>
<h3 id="Maven"><a href="#Maven" class="headerlink" title="Maven"></a>Maven</h3><h4 id="maven插件版本不需要和maven版本对应，每个maven插件都有自己的版本"><a href="#maven插件版本不需要和maven版本对应，每个maven插件都有自己的版本" class="headerlink" title="maven插件版本不需要和maven版本对应，每个maven插件都有自己的版本"></a>maven插件版本不需要和maven版本对应，每个maven插件都有自己的版本</h4><h3 id="个人成长"><a href="#个人成长" class="headerlink" title="个人成长"></a>个人成长</h3><h4 id="PEST分析法"><a href="#PEST分析法" class="headerlink" title="PEST分析法"></a>PEST分析法</h4><p>从政治、经济、社会、技术因素去分析企业管理经营的问题。可以应用到对个人的分析</p>
<h3 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h3><h4 id="命令行英文缩写CLI"><a href="#命令行英文缩写CLI" class="headerlink" title="命令行英文缩写CLI"></a>命令行英文缩写CLI</h4><p>命令行界面（英语：command-line interface，缩写：CLI）</p>
<h4 id="几个磁盘架构知识"><a href="#几个磁盘架构知识" class="headerlink" title="几个磁盘架构知识"></a>几个磁盘架构知识</h4><h5 id="磁盘阵列"><a href="#磁盘阵列" class="headerlink" title="磁盘阵列"></a>磁盘阵列</h5><p>RAID2、3、4较少实际应用，它们大多只在研究领域有实作。</p>
<p><strong>◇RAID 0</strong></p>
<ul>
<li>优点：使用 n 颗硬盘，即可拥有将近 n 倍的读写效能。</li>
<li>缺点：数据安全性较低，同组数组中任一硬盘发生问题就会造成数据遗失。</li>
<li>硬盘数量：最少 2 个。</li>
</ul>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://pic1.zhimg.com/80/v2-29d439a5d1a24127bc48d41e42b093af_720w.jpg?source=1940ef5c"
                      alt="img"
                ></p>
<p><strong>◇RAID 1</strong></p>
<ul>
<li>优点：安全性依照数组里的实体硬盘数量倍数成长。</li>
<li>缺点：空间利用率是所有 RAID 中最没有效率的。</li>
<li>硬盘数量：最少 2 个。</li>
</ul>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://pic4.zhimg.com/80/v2-731c286299fee461a9e0c87ca231df16_720w.jpg?source=1940ef5c"
                      alt="img"
                ></p>
<p><strong>◇RAID 5</strong></p>
<ul>
<li>优点：兼顾空间利用率与安全性。</li>
<li>缺点：需要额外的运算资源，仅能忍受 1 个硬盘损毁。</li>
<li>硬盘数量：至少 3 个。</li>
</ul>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://pic4.zhimg.com/80/v2-2a1d0b4b5db928cd2b8df7f5c50f8455_720w.jpg?source=1940ef5c"
                      alt="img"
                ></p>
<p><strong>◇RAID 6</strong></p>
<ul>
<li>优点：容错硬盘数量比 RAID 5 多 1 颗。</li>
<li>缺点：运算量比 RAID 5 大、空间利用率比 RAID 5 低。</li>
<li>硬盘数量：至少 4 个。</li>
</ul>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://pic2.zhimg.com/80/v2-5187b267e31caac37e08d5a7f958f997_720w.jpg?source=1940ef5c"
                      alt="img"
                ></p>
<h5 id="DAS，NAS，SAN对比"><a href="#DAS，NAS，SAN对比" class="headerlink" title="DAS，NAS，SAN对比"></a>DAS，NAS，SAN对比</h5><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/2022/05/01/%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%AC%94%E8%AE%B0/image-20220305153211208.png"
                      class="" title="image-20220305153211208"
                >




        </div>

        
            <div class="post-copyright-info">
                <div class="article-copyright-info-container">
    <ul>
        <li>Post title：大数据笔记</li>
        <li>Post author：Makarov</li>
        <li>Create time：2022-05-01 14:52:01</li>
        <li>
            Post link：https://makarovd5.github.io/2022/05/01/大数据笔记/
        </li>
        <li>
            Copyright Notice：All articles in this blog are licensed under <a class="license" target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh">BY-NC-SA</a> unless stating additionally.
        </li>
    </ul>
</div>

            </div>
        

        
            <ul class="post-tags-box">
                
                    <li class="tag-item">
                        <a href="/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/">#大数据</a>&nbsp;
                    </li>
                
            </ul>
        

        
            <div class="article-nav">
                
                    <div class="article-prev">
                        <a class="prev"
                           rel="prev"
                           href="/2022/05/01/Keep%E4%B8%BB%E9%A2%98%E9%9C%80%E8%A6%81%E5%AE%89%E8%A3%85%E7%9A%84%E6%8F%92%E4%BB%B6/"
                        >
                            <span class="left arrow-icon flex-center">
                              <i class="fas fa-chevron-left"></i>
                            </span>
                            <span class="title flex-center">
                                <span class="post-nav-title-item">Keep主题需要安装的插件</span>
                                <span class="post-nav-item">Prev posts</span>
                            </span>
                        </a>
                    </div>
                
                
            </div>
        

        
            <div class="comment-container">
                <div class="comments-container">
    <div id="comment-anchor"></div>
    <div class="comment-area-title">
        <i class="fas fa-comments">&nbsp;Comments</i>
    </div>
    

        
            
    <div class="valine-container">
        <script data-pjax
                src="//cdn.jsdelivr.net/npm/valine@latest/dist/Valine.min.js"></script>
        <div id="vcomments"></div>
        <script data-pjax>
            function loadValine() {
                new Valine({
                    el: '#vcomments',
                    appId: '8D1b9t2cR4GHX1haPweuTboM-gzGzoHsz',
                    appKey: 'JPfUErz7BSbEySwRwwm23jLd',
                    meta: ['nick', 'mail', 'link'],
                    avatar: 'wavatar',
                    enableQQ: true,
                    placeholder: '😜 尽情吐槽吧~',
                    lang: 'en'.toLowerCase()
                });

                function getAuthor(language) {
                    switch (language) {
                        case 'en':
                            return 'Author';
                        case 'zh-CN':
                            return '博主';
                        default:
                            return 'Master';
                    }
                }

                // Add "Author" identify
                const getValineDomTimer = setInterval(() => {
                    const vcards = document.querySelectorAll('#vcomments .vcards .vcard');
                    if (vcards.length > 0) {
                        let author = 'Makarov';

                        if (author) {
                            for (let vcard of vcards) {
                                const vnick_dom = vcard.querySelector('.vhead .vnick');
                                const vnick = vnick_dom.innerHTML;
                                if (vnick === author) {
                                    vnick_dom.innerHTML = `${vnick} <span class="author">${getAuthor(KEEP.hexo_config.language)}</span>`
                                }
                            }
                        }
                        clearInterval(getValineDomTimer);
                    } else {
                        clearInterval(getValineDomTimer);
                    }
                }, 2000);
            }

            if ('true') {
                const loadValineTimeout = setTimeout(() => {
                    loadValine();
                    clearTimeout(loadValineTimeout);
                }, 1000);
            } else {
                window.addEventListener('DOMContentLoaded', loadValine);
            }
        </script>
    </div>



        
    
</div>

            </div>
        
    </div>
</div>


                
            </div>

        </div>

        <div class="page-main-content-bottom">
            <footer class="footer">
    <div class="info-container">
        <div class="copyright-info info-item">
            &copy;
            
            2022&nbsp;<i class="fas fa-heart icon-animate"></i>&nbsp;<a href="/">Makarov</a>
        </div>
        
            <script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
            <div class="website-count info-item">
                
                    <span id="busuanzi_container_site_uv">
                        Visitor Count&nbsp;<span id="busuanzi_value_site_uv"></span>&ensp;
                    </span>
                
                
                    <span id="busuanzi_container_site_pv">
                        Totalview&nbsp;<span id="busuanzi_value_site_pv"></span>
                    </span>
                
            </div>
        
        <div class="theme-info info-item">
            Powered by <a target="_blank" href="https://hexo.io">Hexo</a>&nbsp;|&nbsp;Theme&nbsp;<a class="theme-version" target="_blank" href="https://github.com/XPoet/hexo-theme-keep">Keep v3.4.5</a>
        </div>
        
        
    </div>
</footer>

        </div>
    </div>

    
        <div class="post-tools">
            <div class="post-tools-container">
    <ul class="tools-list">
        <!-- TOC aside toggle -->
        
            <li class="tools-item page-aside-toggle">
                <i class="fas fa-outdent"></i>
            </li>
        

        <!-- go comment -->
        
            <li class="go-comment">
                <i class="fas fa-comment"></i>
            </li>
        
    </ul>
</div>

        </div>
    

    <div class="right-bottom-side-tools">
        <div class="side-tools-container">
    <ul class="side-tools-list">
        <li class="tools-item tool-font-adjust-plus flex-center">
            <i class="fas fa-search-plus"></i>
        </li>

        <li class="tools-item tool-font-adjust-minus flex-center">
            <i class="fas fa-search-minus"></i>
        </li>

        <li class="tools-item tool-expand-width flex-center">
            <i class="fas fa-arrows-alt-h"></i>
        </li>

        <li class="tools-item tool-dark-light-toggle flex-center">
            <i class="fas fa-moon"></i>
        </li>

        <!-- rss -->
        

        
            <li class="tools-item tool-scroll-to-top flex-center">
                <i class="fas fa-arrow-up"></i>
            </li>
        

        <li class="tools-item tool-scroll-to-bottom flex-center">
            <i class="fas fa-arrow-down"></i>
        </li>
    </ul>

    <ul class="exposed-tools-list">
        <li class="tools-item tool-toggle-show flex-center">
            <i class="fas fa-cog fa-spin"></i>
        </li>
        
    </ul>
</div>

    </div>

    
        <aside class="page-aside">
            <div class="post-toc-wrap">
    <div class="post-toc">
        <ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%A4%A7%E6%95%B0%E6%8D%AE"><span class="nav-number">1.</span> <span class="nav-text">大数据</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%BD%93%E5%89%8D%E8%A7%82%E7%9C%8B%E9%9B%86%E6%95%B0%EF%BC%9A47"><span class="nav-number">1.1.</span> <span class="nav-text">当前观看集数：47</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%AE%80%E4%BB%8B"><span class="nav-number">1.2.</span> <span class="nav-text">简介</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE"><span class="nav-number">1.3.</span> <span class="nav-text">环境配置</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%9F%BA%E7%A1%80Linux%E9%85%8D%E7%BD%AE"><span class="nav-number">1.3.1.</span> <span class="nav-text">基础Linux配置</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Java%E9%85%8D%E7%BD%AE"><span class="nav-number">1.3.2.</span> <span class="nav-text">Java配置</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Hadoop%E9%85%8D%E7%BD%AE"><span class="nav-number">1.3.3.</span> <span class="nav-text">Hadoop配置</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Hadoop"><span class="nav-number">1.4.</span> <span class="nav-text">Hadoop</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%9C%80%E5%88%9D%E4%BD%BF%E7%94%A8"><span class="nav-number">1.4.1.</span> <span class="nav-text">最初使用</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#shell%E8%84%9A%E6%9C%AC%E4%B8%80%E9%94%AE%E5%90%AF%E5%81%9C"><span class="nav-number">1.4.1.1.</span> <span class="nav-text">shell脚本一键启停</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%90%AF%E5%8A%A8%E5%87%BA%E7%8E%B0%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BE%97%E7%9C%8B%E6%97%A5%E5%BF%97"><span class="nav-number">1.4.1.2.</span> <span class="nav-text">启动出现问题记得看日志</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Web-UI"><span class="nav-number">1.4.1.3.</span> <span class="nav-text">Web UI</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E9%87%8D%E8%A6%81%E7%89%B9%E6%80%A7"><span class="nav-number">1.4.2.</span> <span class="nav-text">重要特性</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%A8%A1%E6%8B%9F%E5%AE%9E%E7%8E%B0%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E5%AD%98%E5%82%A8"><span class="nav-number">1.4.3.</span> <span class="nav-text">模拟实现分布式文件存储</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#HDFS"><span class="nav-number">1.5.</span> <span class="nav-text">HDFS</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#HDFS%E8%AE%BE%E8%AE%A1%E7%9B%AE%E6%A0%87"><span class="nav-number">1.5.1.</span> <span class="nav-text">HDFS设计目标</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Shell"><span class="nav-number">1.5.2.</span> <span class="nav-text">Shell</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%8D%8F%E8%AE%AE"><span class="nav-number">1.5.2.1.</span> <span class="nav-text">文件系统协议</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4"><span class="nav-number">1.5.2.2.</span> <span class="nav-text">常用命令</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%88%9B%E5%BB%BA%E6%96%87%E4%BB%B6%E5%A4%B9"><span class="nav-number">1.5.2.2.1.</span> <span class="nav-text">创建文件夹</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E6%9F%A5%E7%9C%8B%E6%8C%87%E5%AE%9A%E7%9B%AE%E5%BD%95%E4%B8%8B%E5%86%85%E5%AE%B9"><span class="nav-number">1.5.2.2.2.</span> <span class="nav-text">查看指定目录下内容</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E4%B8%8A%E4%BC%A0%E6%96%87%E4%BB%B6%E5%88%B0HDFS%E6%8C%87%E5%AE%9A%E7%9B%AE%E5%BD%95%E4%B8%8B"><span class="nav-number">1.5.2.2.3.</span> <span class="nav-text">上传文件到HDFS指定目录下</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E6%9F%A5%E7%9C%8BHDFS%E6%96%87%E4%BB%B6%E5%86%85%E5%AE%B9"><span class="nav-number">1.5.2.2.4.</span> <span class="nav-text">查看HDFS文件内容</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E4%B8%8B%E8%BD%BDHDFS%E6%96%87%E4%BB%B6"><span class="nav-number">1.5.2.2.5.</span> <span class="nav-text">下载HDFS文件</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E6%8B%B7%E8%B4%9DHDFS%E6%96%87%E4%BB%B6"><span class="nav-number">1.5.2.2.6.</span> <span class="nav-text">拷贝HDFS文件</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E8%BF%BD%E5%8A%A0%E6%95%B0%E6%8D%AE%E5%88%B0HDFS%E6%96%87%E4%BB%B6%E4%B8%AD"><span class="nav-number">1.5.2.2.7.</span> <span class="nav-text">追加数据到HDFS文件中</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#HDFS%E6%95%B0%E6%8D%AE%E7%A7%BB%E5%8A%A8%E6%93%8D%E4%BD%9C"><span class="nav-number">1.5.2.2.8.</span> <span class="nav-text">HDFS数据移动操作</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E6%9F%A5%E7%9C%8BHDFS%E7%A3%81%E7%9B%98%E4%BD%BF%E7%94%A8%E6%83%85%E5%86%B5"><span class="nav-number">1.5.2.2.9.</span> <span class="nav-text">查看HDFS磁盘使用情况</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E6%98%BE%E7%A4%BA%E7%9B%AE%E5%BD%95%E4%B8%AD%E6%89%80%E6%9C%89%E6%96%87%E4%BB%B6%E5%A4%A7%E5%B0%8F"><span class="nav-number">1.5.2.2.10.</span> <span class="nav-text">显示目录中所有文件大小</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E4%BF%AE%E6%94%B9HDFS%E6%96%87%E4%BB%B6%E5%89%AF%E6%9C%AC%E4%B8%AA%E6%95%B0"><span class="nav-number">1.5.2.2.11.</span> <span class="nav-text">修改HDFS文件副本个数</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%91%BD%E4%BB%A4%E5%AE%98%E6%96%B9%E6%8C%87%E5%AF%BC%E6%96%87%E6%A1%A3"><span class="nav-number">1.5.2.2.12.</span> <span class="nav-text">命令官方指导文档</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#HDFS-Java-%E5%AE%A2%E6%88%B7%E7%AB%AF-API"><span class="nav-number">1.5.3.</span> <span class="nav-text">HDFS Java 客户端 API</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%AE%A2%E6%88%B7%E7%AB%AF%E6%A0%B8%E5%BF%83%E7%B1%BB"><span class="nav-number">1.5.3.1.</span> <span class="nav-text">客户端核心类</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E9%85%8D%E7%BD%AEMaven"><span class="nav-number">1.5.3.2.</span> <span class="nav-text">配置Maven</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%BF%9E%E6%8E%A5HDFS"><span class="nav-number">1.5.3.3.</span> <span class="nav-text">连接HDFS</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E4%BF%AE%E6%94%B9%E9%BB%98%E8%AE%A4%E7%94%A8%E6%88%B7"><span class="nav-number">1.5.3.3.1.</span> <span class="nav-text">修改默认用户</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%88%9B%E5%BB%BA%E6%96%87%E4%BB%B6%E5%A4%B9-1"><span class="nav-number">1.5.3.3.2.</span> <span class="nav-text">创建文件夹</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E4%B8%8A%E4%BC%A0%E6%96%87%E4%BB%B6"><span class="nav-number">1.5.3.3.3.</span> <span class="nav-text">上传文件</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E4%B8%8B%E8%BD%BD%E6%96%87%E4%BB%B6"><span class="nav-number">1.5.3.3.4.</span> <span class="nav-text">下载文件</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Log4J"><span class="nav-number">1.5.3.4.</span> <span class="nav-text">Log4J</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#Log4j%E5%85%B7%E6%9C%89%E4%B8%89%E4%B8%AA%E4%B8%BB%E8%A6%81%E7%BB%84%E4%BB%B6"><span class="nav-number">1.5.3.4.1.</span> <span class="nav-text">Log4j具有三个主要组件</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E6%97%A5%E5%BF%97%E7%BA%A7%E5%88%AB"><span class="nav-number">1.5.3.4.2.</span> <span class="nav-text">日志级别</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E7%A8%8B%E5%BA%8F%E4%B8%AD%E4%BD%BF%E7%94%A8Log4j"><span class="nav-number">1.5.3.4.3.</span> <span class="nav-text">程序中使用Log4j</span></a><ol class="nav-child"><li class="nav-item nav-level-6"><a class="nav-link" href="#%E9%A1%B9%E7%9B%AE%E4%B8%AD%E5%BC%95%E5%85%A5log4j%E7%9A%84jar%E5%8C%85"><span class="nav-number">1.5.3.4.3.1.</span> <span class="nav-text">项目中引入log4j的jar包</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6log4j-properties"><span class="nav-number">1.5.3.4.3.2.</span> <span class="nav-text">配置文件log4j.properties</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#%E4%BB%A3%E7%A0%81%E4%B8%AD%E4%BD%BF%E7%94%A8"><span class="nav-number">1.5.3.4.3.3.</span> <span class="nav-text">代码中使用</span></a></li></ol></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Google-option"><span class="nav-number">1.5.3.5.</span> <span class="nav-text">Google-option</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%88%86%E6%83%85%E6%95%B0%E6%8D%AE%E4%B8%8A%E6%8A%A5%E6%A1%88%E4%BE%8B"><span class="nav-number">1.5.3.6.</span> <span class="nav-text">舆情数据上报案例</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E7%8E%AF%E5%A2%83%E5%87%86%E5%A4%87"><span class="nav-number">1.5.3.6.1.</span> <span class="nav-text">环境准备</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%AE%9E%E7%8E%B0%E7%94%9F%E6%88%90%E6%95%B0%E6%8D%AE%E9%87%87%E9%9B%86%E4%BB%BB%E5%8A%A1"><span class="nav-number">1.5.3.6.2.</span> <span class="nav-text">实现生成数据采集任务</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%AE%9E%E7%8E%B0%E6%89%A7%E8%A1%8C%E6%95%B0%E6%8D%AE%E4%B8%8A%E6%8A%A5%E4%BB%BB%E5%8A%A1"><span class="nav-number">1.5.3.6.3.</span> <span class="nav-text">实现执行数据上报任务</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Hadoop%E5%9F%BA%E5%87%86%E6%B5%8B%E8%AF%95"><span class="nav-number">1.5.4.</span> <span class="nav-text">Hadoop基准测试</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%86%99%E5%85%A5%E5%9F%BA%E5%87%86%E6%B5%8B%E8%AF%95"><span class="nav-number">1.5.4.1.</span> <span class="nav-text">写入基准测试</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%AF%BB%E5%8F%96%E5%9F%BA%E5%87%86%E6%B5%8B%E8%AF%95"><span class="nav-number">1.5.4.2.</span> <span class="nav-text">读取基准测试</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%B8%85%E9%99%A4%E6%B5%8B%E8%AF%95%E6%95%B0%E6%8D%AE"><span class="nav-number">1.5.4.3.</span> <span class="nav-text">清除测试数据</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%B5%8B%E8%AF%95%E7%BB%93%E6%9E%9C%E5%90%84%E9%A1%B9%E6%95%B0%E5%80%BC%E7%9A%84%E6%84%8F%E4%B9%89"><span class="nav-number">1.5.4.4.</span> <span class="nav-text">测试结果各项数值的意义</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#HDFS%E5%B7%A5%E4%BD%9C%E6%B5%81%E7%A8%8B%E4%B8%8E%E6%9C%BA%E5%88%B6"><span class="nav-number">1.5.5.</span> <span class="nav-text">HDFS工作流程与机制</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#HDFS%E9%9B%86%E7%BE%A4%E8%A7%92%E8%89%B2%E4%B8%8E%E8%81%8C%E8%B4%A3"><span class="nav-number">1.5.5.1.</span> <span class="nav-text">HDFS集群角色与职责</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#NameNode"><span class="nav-number">1.5.5.1.1.</span> <span class="nav-text">NameNode</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#DataNode"><span class="nav-number">1.5.5.1.2.</span> <span class="nav-text">DataNode</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#SecondaryNameNode"><span class="nav-number">1.5.5.1.3.</span> <span class="nav-text">SecondaryNameNode</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#HDFS%E8%AF%BB%E5%86%99%E6%95%B0%E6%8D%AE%E6%B5%81%E7%A8%8B"><span class="nav-number">1.5.5.2.</span> <span class="nav-text">HDFS读写数据流程</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#Pipeline%E7%AE%A1%E9%81%93"><span class="nav-number">1.5.5.2.1.</span> <span class="nav-text">Pipeline管道</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#ACK%E5%BA%94%E7%AD%94%E5%93%8D%E5%BA%94"><span class="nav-number">1.5.5.2.2.</span> <span class="nav-text">ACK应答响应</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E9%BB%98%E8%AE%A43%E5%89%AF%E6%9C%AC%E5%AD%98%E5%82%A8%E7%AD%96%E7%95%A5"><span class="nav-number">1.5.5.2.3.</span> <span class="nav-text">默认3副本存储策略</span></a></li></ol></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#MapReduce"><span class="nav-number">1.6.</span> <span class="nav-text">MapReduce</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%85%B6%E4%BB%96%E9%A2%86%E5%9F%9F"><span class="nav-number">1.7.</span> <span class="nav-text">其他领域</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Java"><span class="nav-number">1.7.1.</span> <span class="nav-text">Java</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#lambda%E7%9A%84%E4%BD%BF%E7%94%A8"><span class="nav-number">1.7.1.1.</span> <span class="nav-text">lambda的使用</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#FileUtils%E7%9A%84%E4%BD%BF%E7%94%A8"><span class="nav-number">1.7.1.2.</span> <span class="nav-text">FileUtils的使用</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#FileUtils-moveFile"><span class="nav-number">1.7.1.2.1.</span> <span class="nav-text">FileUtils.moveFile</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%8D%95%E8%8E%B7%E5%BC%82%E5%B8%B8-%E5%86%8D%E6%AC%A1%E6%8A%9B%E5%87%BA%E5%BC%82%E5%B8%B8%E4%B8%8E%E5%BC%82%E5%B8%B8%E9%93%BE"><span class="nav-number">1.7.1.3.</span> <span class="nav-text">捕获异常+再次抛出异常与异常链</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#JAVA-IO"><span class="nav-number">1.7.1.4.</span> <span class="nav-text">JAVA IO</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%88%9B%E5%BB%BA%E6%96%87%E4%BB%B6"><span class="nav-number">1.7.1.4.1.</span> <span class="nav-text">创建文件</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E8%8E%B7%E5%8F%96%E6%96%87%E4%BB%B6%E4%BF%A1%E6%81%AF"><span class="nav-number">1.7.1.4.2.</span> <span class="nav-text">获取文件信息</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E7%9B%AE%E5%BD%95%E6%93%8D%E4%BD%9C"><span class="nav-number">1.7.1.4.3.</span> <span class="nav-text">目录操作</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Linux"><span class="nav-number">1.7.2.</span> <span class="nav-text">Linux</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#proc%E7%9B%AE%E5%BD%95"><span class="nav-number">1.7.2.1.</span> <span class="nav-text">proc目录</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#scp%E5%91%BD%E4%BB%A4%EF%BC%9A%E5%9F%BA%E4%BA%8Essh%E8%BF%9C%E7%A8%8B%E6%8B%B7%E8%B4%9D"><span class="nav-number">1.7.2.2.</span> <span class="nav-text">scp命令：基于ssh远程拷贝</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#FinalShell%E7%9A%84%E5%91%BD%E4%BB%A4%E7%BC%96%E8%BE%91%E5%99%A8%E8%83%BD%E5%8F%91%E9%80%81%E5%88%B0%E5%85%A8%E9%83%A8%E4%BC%9A%E8%AF%9D"><span class="nav-number">1.7.2.3.</span> <span class="nav-text">FinalShell的命令编辑器能发送到全部会话</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#IDEA"><span class="nav-number">1.7.3.</span> <span class="nav-text">IDEA</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#pom%E6%8A%A5%E9%94%99"><span class="nav-number">1.7.3.1.</span> <span class="nav-text">pom报错</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%BF%AB%E9%80%9F%E9%80%89%E4%B8%AD%E4%B8%80%E8%A1%8C"><span class="nav-number">1.7.3.2.</span> <span class="nav-text">快速选中一行</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Maven"><span class="nav-number">1.7.4.</span> <span class="nav-text">Maven</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#maven%E6%8F%92%E4%BB%B6%E7%89%88%E6%9C%AC%E4%B8%8D%E9%9C%80%E8%A6%81%E5%92%8Cmaven%E7%89%88%E6%9C%AC%E5%AF%B9%E5%BA%94%EF%BC%8C%E6%AF%8F%E4%B8%AAmaven%E6%8F%92%E4%BB%B6%E9%83%BD%E6%9C%89%E8%87%AA%E5%B7%B1%E7%9A%84%E7%89%88%E6%9C%AC"><span class="nav-number">1.7.4.1.</span> <span class="nav-text">maven插件版本不需要和maven版本对应，每个maven插件都有自己的版本</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%B8%AA%E4%BA%BA%E6%88%90%E9%95%BF"><span class="nav-number">1.7.5.</span> <span class="nav-text">个人成长</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#PEST%E5%88%86%E6%9E%90%E6%B3%95"><span class="nav-number">1.7.5.1.</span> <span class="nav-text">PEST分析法</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%85%B6%E4%BB%96"><span class="nav-number">1.7.6.</span> <span class="nav-text">其他</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%91%BD%E4%BB%A4%E8%A1%8C%E8%8B%B1%E6%96%87%E7%BC%A9%E5%86%99CLI"><span class="nav-number">1.7.6.1.</span> <span class="nav-text">命令行英文缩写CLI</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%87%A0%E4%B8%AA%E7%A3%81%E7%9B%98%E6%9E%B6%E6%9E%84%E7%9F%A5%E8%AF%86"><span class="nav-number">1.7.6.2.</span> <span class="nav-text">几个磁盘架构知识</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E7%A3%81%E7%9B%98%E9%98%B5%E5%88%97"><span class="nav-number">1.7.6.2.1.</span> <span class="nav-text">磁盘阵列</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#DAS%EF%BC%8CNAS%EF%BC%8CSAN%E5%AF%B9%E6%AF%94"><span class="nav-number">1.7.6.2.2.</span> <span class="nav-text">DAS，NAS，SAN对比</span></a></li></ol></li></ol></li></ol></li></ol></li></ol>
    </div>
</div>
        </aside>
    

    <div class="image-viewer-container">
    <img src="">
</div>


    
        <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
          <span class="search-input-field-pre">
            <i class="fas fa-keyboard"></i>
          </span>
            <div class="search-input-container">
                <input autocomplete="off"
                       autocorrect="off"
                       autocapitalize="off"
                       placeholder="Search..."
                       spellcheck="false"
                       type="search"
                       class="search-input"
                >
            </div>
            <span class="popup-btn-close">
                <i class="fas fa-times"></i>
            </span>
        </div>
        <div id="search-result">
            <div id="no-result">
                <i class="fas fa-spinner fa-pulse fa-5x fa-fw"></i>
            </div>
        </div>
    </div>
</div>

    

</main>



<script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.4.5/source/js/utils.js"></script><script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.4.5/source/js/main.js"></script><script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.4.5/source/js/header-shrink.js"></script><script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.4.5/source/js/back2top.js"></script><script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.4.5/source/js/dark-light-toggle.js"></script>


    <script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.4.5/source/js/local-search.js"></script>



    <script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.4.5/source/js/code-copy.js"></script>



    <script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.4.5/source/js/lazyload.js"></script>


<div class="post-scripts pjax">
    
        <script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.4.5/source/js/left-side-toggle.js"></script><script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.4.5/source/js/libs/anime.min.js"></script><script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.4.5/source/js/toc.js"></script>
    
</div>


    <script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.4.5/source/js/libs/pjax.min.js"></script>
<script>
    window.addEventListener('DOMContentLoaded', () => {
        window.pjax = new Pjax({
            selectors: [
                'head title',
                '.page-container',
                '.pjax'
            ],
            history: true,
            debug: false,
            cacheBust: false,
            timeout: 0,
            analytics: false,
            currentUrlFullReload: false,
            scrollRestoration: false,
            // scrollTo: true,
        });

        document.addEventListener('pjax:send', () => {
            KEEP.utils.pjaxProgressBarStart();
        });

        document.addEventListener('pjax:complete', () => {
            KEEP.utils.pjaxProgressBarEnd();
            window.pjax.executeScripts(document.querySelectorAll('script[data-pjax], .pjax script'));
            KEEP.refresh();
        });
    });
</script>



</body>
</html>
